---
title: "Statistical analysis of cancer driver gene prediction"
author: "Collin Tokheim"
date: "`r Sys.Date()`"
output: rmarkdown::pdf_document
vignette: >
  %\VignetteIndexEntry{Statistical analysis of predicting cancer driver genes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

Identifying genes with more mutations then expected has been central methodology for identifying putative cancer driver genes in exome sequencing studies of cancer samples. Identifying significantly mutated genes (SMG) fundamentally relies on estimating a background mutation rate. Mutation rate varies over more than 2 orders of magnitude providing a substantial statistical estimation challenge. However, recent methods have taken an alternative approach known as "ratio-metric". Ratio-metric methods examine specific compositions of mutations normalized by the total number of mutations occurring in the gene. Regardless of methodology, analysis not accounting for the uncertainty in mutation parameters yields overly optimistic assessments. In this package, we examine statistical power (either with known or uncertain mutation rate) and false positives induced by unaccounted variation in mutation rate.

## Relevant parameters

### Significantly mutated gene (SMG)

SMG methods rely on estimating a background mutation rate (BMR), which in this package is represented by the parameter mu or "rate". A simple model for the accumulation of non-silent mutations in genes uses a binomial distribution that has *fixed* rate over the length of the gene. The `L` parameter controls the number of bases for an average gene (for simplicity genes have the same length). Because approximately 3/4 of point mutations lead to non-silent changes, an effective length `Leff=3/4*L` (roughly this fraction is expected purely based on the codon table). The mutation rate varies substantially depending on the particular cancer type of interest, so the mutation rate should be varied accordingly. An additional complexity is the mutation rate varies substantially over genes, with gene expression and replication timing correlated with mutation rate. To compensate for this variation above expected purely based on the aggregate samples in the tumor type, Lawrence *et al.* proposed the nominal tumor type mutation rate should be adjusted by a gene specfic multiplication factor `fg=3.9`, representing the 90th percentile of genes. Internally cancerSeqStudy does not apply this multiplication factor, so users should adjust for this prior to input. 

### Ratio-metric approach

In contrast to SMGs, ratio-metric methods focuse on particular types of mutations occurring in a gene. For example, this could be the ammount of "inactivating" mutations (nonsense, splice site, or frameshift indels). By examining somatic mutations, there will be a certain proportion `P` of total mutations that will be those of interest. Using the same parameterizations for gene length `L` and mutation rate mu as in the SMG analysis, the behavior of genes with high values of `P` can be analyzed.

### Parameter uncertainty

The above scenario reflects a known fixed mutation rate. Realistically, however, the background mutation rate is estimated and can be uncertain due to both technical and biological factors. To account for uncertainty, a certain coefficient of variation (CV) for the mutation rate can be allowed using a beta-binomial distribution. To move from mutation rate and CV to $\alpha$ and $\beta$ (typical parameterization of a beta-binomial), the `rateCvToAlphaBeta` function is used.

```{r, fig.show='hold'}
library(cancerSeqStudy)

# calculate the mutation rate
fg <- 3.9
nominal.rate <- 3e-6
adjusted.rate <- fg * nominal.rate

# record the coefficient of variation
cv <- .2

# calculate the alpha and beta parameters
rateCvToAlphaBeta(adjusted.rate, cv)
```

### Statistical Power

Statistical power calculations involve several relevant parameters, where the last parameter is solved in terms of the other known parameters. 

* power
* sample size
* effect size

The `*RequiredSampleSize` functions (\*="smg" or "ratiometric" followed by "Bbd" or "Binom", e.g., "smgBbd") calculate the needed number of samples to achieve a desired power for an effect size at a given significance level. Here, effect size is always the fraction of samples above the background mutation rate (BMR). So .02 represents mutated in 2% additional samples above expected from BMR.  While the `*PoweredEffectSize` reports the effect size for wich there is sufficient power at a given sample size. Lastly, `*.power` functions (\*= "smg" or "ratiometric", followed by either ".binom" or ".bbd", e.g., "smg.binom") solve for statistical power based on a given sample size and effect size.

### Expected false positives

In the situation where there is additional unaccounted variability in the mutation rate not captured by the model, then it is expected there will be inflated false positives. To evaluate the expected number of false positives, a binomial model is compared with a beta-binomial with a certain level of residual uncertainty in the mutation rate. The beta-binomial represents the actual true variation, while the binomial model represents that utilized for a SMG analysis. In this scenario the critical value establishing the threshold for statistical significance is established by the binomial model, and the probability that a beta-binomial reaches this baseline is calculated. Expected false positives for ratio-metric methods are computed similarly, except the variable which has variablitity is `P` rather than the mutation rate. Assuming a total number of genes (18,500 by default), the expected number of false positive significantly mutated genes is simply the probability times the number of genes.

## SMG method

### Sample Size Calculation

An important aspect of designing cancer exome seqeuncing studies is to determine how many cancer samples are required for sufficient power to detect driver genes present at a certain prevalence.

#### Assuming an exact mutation rate

In general the mutation rate is not precisely known, but could be assumed to be known for the sake of power calculations. This results in an overly optimistic assessment of the required number of cancer samples. In the known mutation rate scenario, an exact binomial power calculation is performed.

```{r, fig.show='hold'}
library(cancerSeqStudy)

# setup parameters
samp.sizes <- seq(100, 4000, by=100)
desired.power <- .9
eff.size <- .02  # fraction of samples above background
mut.rate <- 1e-5
signif.level <- 5e-6  # roughly a bonferoni corrected significance level

smgBinomRequiredSampleSize(desired.power, mut.rate, samp.sizes, eff.size, signif.level)
```

#### Accounting for uncertain mutation rate

Adjusting for uncertainty in mutation rate better represents the actual required number of sequenced samples. To handle uncertain mutation rates (with a certain coefficient of variation), a beta-binomial power test is performed.

```{r, fig.show='hold'}
# setup parameters
cv <- .2  # coefficient of variation for mutation rate

smgBbdRequiredSampleSize(desired.power, mut.rate, cv, samp.sizes, eff.size)
```

Notice the minimum required samples raised from 1,500 to 3,500 by accounting for uncertainty of mutation rate with a coefficient of variation of .2.

### Calculating powered effect size

If you already have a certain number of samples, often it is helpful to understand the extent to which rare significantly mutated genes are characterized. 

```{r, fig.show='hold'}
# setup parameters
possible.eff.sizes <- seq(.01, .2, by=.01)  # fraction of samples above background
num.samples <- 1000  # number of samples in study

smgBbdPoweredEffectSize(possible.eff.sizes, desired.power, mut.rate, cv, num.samples, signif.level)
```

In this example, drivers present in 4% of samples above background mutation rate have sufficient power to be detected.

### Expected false positives

```{r, fig.show='hold'}
bbd.params <- rateCvToAlphaBeta(mut.rate, cv)
smg.binom.false.pos(bbd.params$alpha, bbd.params$beta, samp.sizes)
```

Here, the total number of genes (`num.genes`) was left at the default of 18,500, and likewise for the significance level (5e-6) and effective gene length (1500*3/4).

## Ratio-metric method

### Sample Size Calculation

Since ratio-metric methods represent an alternative computational approach, they may have differences in statistical power compared to SMG methods.

#### Assuming an exact proportion

The expected background proportion out of total mutations in a gene that fall into a specific type is generally more stable than mutation rate, e.g. presumed inactivating mutations (nonsense, splice site, lost stop/start, and frameshift indels). In the fixed mutation proportion scenario, an exact binomial power calculation is performed.

```{r, fig.show='hold'}
# setup parameters
samp.sizes <- seq(100, 1000, by=10)
desired.power <- .9
eff.size <- .02  # fraction of samples above background
mut.rate <- 1e-5
signif.level <- 5e-6  # roughly a bonferoni corrected significance level
p <- .107  # 10.7% is approximately the percentage of inactivating mutations

ratiometricBinomRequiredSampleSize(p, desired.power, samp.sizes, mut.rate,  
                                   eff.size, signif.lvl=signif.level)
```

#### Accounting for uncertainty

Adjusting for uncertainty in the proprotion `P` can represent heterogeneity in acquiring mutations. To handle uncertainty in `P` (with a certain coefficient of variation), a beta-binomial power test is performed.

```{r, fig.show='hold'}
# setup parameters
cv <- .2  # coefficient of variation for ratio-metric proportion

ratiometricBbdRequiredSampleSize(p, cv, desired.power, samp.sizes, 
                                 mut.rate, eff.size)
```

Notice the minimum required samples raised from 770 to 890 by accounting for uncertainty of proportion of inactivating mutations with a coefficient of variation of .2. Both numbers are considerably lower than an approach based on mutation rate (1500 and 3500, respectively).

### Calculating powered effect size

If you already have a certain number of samples, often it is helpful to understand the extent to which rare significantly mutated genes are characterized. 

```{r, fig.show='hold'}
# setup parameters
possible.eff.sizes <- seq(.01, .1, by=.005)  # fraction of samples above background
num.samples <- 600  # number of samples in study

ratiometricBbdPoweredEffectSize(possible.eff.sizes, desired.power, p, cv, 
                                mut.rate, num.samples, signif.level)
```

In this example, drivers present with the ratio-metric feature of interest at 3% of samples above background mutation rate have sufficient power to be detected with 600 samples.

### Expected false positives

```{r, fig.show='hold'}
bbd.params <- rateCvToAlphaBeta(p, cv)
samp.sizes <- seq(200, 4000, by=200)
ratiometric.binom.false.pos(bbd.params$alpha, bbd.params$beta, 
                            samp.sizes, mut.rate)
```

Here, the total number of genes (`num.genes`) was left at the default of 18,500, and likewise for the significance level (5e-6) and effective gene length (1500*3/4).

## Systematically examining power and false postives

To fully understand the effects on power and false positives, a variable sweep over a grid of potential values can be done. This is best done in parallel on a server with multiple cores. Reducing the number of evaluate mutation rates or the effective number of sample sizes evaluated will substantially increase speed, but will provide lower resolution on the shape of statistical power and false positives. One approach is to download the source files from github and run cancerSeqStudy.R as a script. The following command runs the analysis for significantly mutated gene approaches.

```{r, engine = 'bash', eval = FALSE}
$ cd cancerSeqStudy
$ Rscript R/cancerSeqStudy.R -c 10 -o myoutput.txt
```

Where `-c` expressess the number of cores to use, and `-o` designates the output file name.
Running the analysis for ratio-metric method requires additionally passing the fraction of mutations expected to be of the category of interest using the `-r` parameter.

```{r, engine = 'bash', eval = FALSE}
$ cd cancerSeqStudy
$ Rscript R/cancerSeqStudy.R -c 10 -r .107 -o myoutput.txt
```

Where .107 represents 10.7% of mutations, a typical percentage for inactivating mutations. To change additional parameters which are evaluated requires changing the cancerSeqStudy script. Alternatively, cancerSeqStudy may be installed and can be run with creating a new R file that uses the installed library. An extensive parameter sweep is shown below.

```{r, eval=FALSE}
library(cancerSeqStudy)
library(reshape2)
library(parallel)

#############################
# running options
#############################
output <- "statistical_analysis_output.txt"  # file name to save output
num.cores <- 1  # increase on multi-core computer to run faster!!!

#############################
# define the model params
#############################
# whether to evaluate a SMG or ratio-metric approach
cmdType <- "smg"  # alternative is "ratio-metric"

# long list of rates to be evaluated
rate <- c(.1e-6, .2e-6, .3e-6, .4e-6, .5e-6, .7e-6, .8e-6, 1e-6, 1.25e-6, 1.5e-6, 1.75e-6, 2e-6, 2.25e-6, 2.5e-6, 2.75e-6, 3e-6, 3.5e-6, 4e-6,
          4.5e-6, 5e-6, 5.5e-6, 6e-6, 6.5e-6, 7e-6, 7.5e-6, 8e-6, 8.5e-6, 9e-6, 10e-6, 11e-6, 12e-6)
fg <- 3.9  # an adjustment factor that lawrence et al used for variable gene length
rate <- fg*rate  # nominal rates are adjusted (will have to adjust back after analysis is done)

# model parameters
nonsilentFactor <- 3/4  # roughly the fraction of non-silent mutations
L <- 1500  # same length as used in lawrence et al. paper
Leff <- L * nonsilentFactor
desired.power <- .9  # aka 90% power
possible.cvs <- c(.05, .1, .2)  # coefficient of variation for mutation rate per base
effect.sizes <- c(.01, .02, .05)  # fraction of samples above background
alpha.levels <- c(5e-6)  # list for level of significance

# setting up the sample sizes to check
N <- 25000
by.step <- 25
samp.sizes <- seq(by.step, N, by=by.step)  # grid of sample sizes to check

##################################
# Loop through different params
##################################
param.list <- list()
counter <- 1
for (i in 1:length(rate)){
  # loop over effect sizes
  for (effect.size in effect.sizes){
    # loop over alpha levels
    for (alpha.level in alpha.levels){
      if(cmdType=="smg"){
        param.list[[counter]] <- c(rate[i], effect.size, alpha.level)
      }else {
        param.list[[counter]] <- c(opt$ratioMetric, rate[i], effect.size, alpha.level)
      }
      counter <- counter + 1
    }
  }
}
  
############################
# run analysis
############################
result.list <- mclapply(param.list, runAnalysisList, mc.cores=num.cores,
                        analysisType=cmdType, samp.sizes=samp.sizes, 
                        desired.power=desired.power,
                        Leff=Leff, possible.cvs=possible.cvs)
result.df <- do.call("rbind", result.list)

# adjust mutation rates back to the average
result.df$mutation.rate <- result.df$mutation.rate / fg
# convert to factor
result.df$mutation.rate <- factor(result.df$mutation.rate, levels=unique(result.df$mutation.rate))
result.df$effect.size <- factor(result.df$effect.size, levels=unique(result.df$effect.size))

######################
# Save result to text file
######################
write.table(result.df, output, sep='\t')
```

